{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_participants(base_path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan base_path for participant folders name,\n",
    "    and return them sorted by their numeric ID.\n",
    "    \"\"\"\n",
    "    all_dirs = [\n",
    "        d for d in os.listdir(base_path)\n",
    "        if os.path.isdir(os.path.join(base_path, d))\n",
    "    ]\n",
    "    # extract number with regex, sort numerically\n",
    "    participants = sorted(\n",
    "        all_dirs,\n",
    "        key=lambda n: int(re.search(r'\\d+', n).group())\n",
    "    )\n",
    "    return participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌳 Data from situ experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Raw data for all Participant containing Muse EEG, Empatica ACC/BVP/EDA/TEMP, PsychoPy logs & questionnaires, stretched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_situ_data_raw(\n",
    "    base_path: str,\n",
    "    participants: list[str],\n",
    "    modalities: list[str] = ['Empatica', 'Muse', 'Questionnaire', 'Stretched']\n",
    ") -> None:\n",
    "    \n",
    "    for p in participants:\n",
    "        print(f\"\\n=== Participant: {p} ===\")\n",
    "        raw_root = os.path.join(base_path, p, 'situ', 'Raw')\n",
    "\n",
    "        for mod in modalities:\n",
    "            print(f\"\\n-- {mod} CSV files --\")\n",
    "            mod_path = os.path.join(raw_root, mod)\n",
    "\n",
    "            if not os.path.isdir(mod_path):\n",
    "                print(f\"   ✗ Missing folder: {mod_path}\")\n",
    "                continue\n",
    "\n",
    "            # find CSVs only\n",
    "            csvs = [f for f in os.listdir(mod_path)\n",
    "                    if f.lower().endswith('.csv')]\n",
    "            if not csvs:\n",
    "                print(\"   (no CSVs here)\")\n",
    "                continue\n",
    "\n",
    "            for fname in csvs:\n",
    "                full = os.path.join(mod_path, fname)\n",
    "                print(f\"  • {fname}\")\n",
    "                try:\n",
    "                    df = pd.read_csv(full)\n",
    "                    print(df.head(), \"\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠ Couldn’t read {fname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Labeled, Preprocessed, Features data from situ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled contains synchronized, segmented raw data per task; Preprocessed contains cleaned & preprocessed labeled data; Features contains features extracted from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_situ_data_labeled_preprocessed_features(\n",
    "    base_path: str,\n",
    "    participants: list[str],\n",
    "    situ_subfolder: str\n",
    ") -> None:\n",
    "    \n",
    "    for p in participants:\n",
    "        print(f\"\\n=== Participant: {p} | Situ/{situ_subfolder} ===\")\n",
    "        root = os.path.join(base_path, p, 'Situ', situ_subfolder)\n",
    "\n",
    "        if not os.path.isdir(root):\n",
    "            print(f\"   ✗ No {situ_subfolder} data for {p}\")\n",
    "            continue\n",
    "\n",
    "        tasks = [\n",
    "            d for d in os.listdir(root)\n",
    "            if os.path.isdir(os.path.join(root, d))\n",
    "        ]\n",
    "        if not tasks:\n",
    "            print(\"   (no task folders here)\")\n",
    "            continue\n",
    "\n",
    "        for task in tasks:\n",
    "            task_path = os.path.join(root, task)\n",
    "            print(f\"\\n-- {task} --\")\n",
    "            pickles = [\n",
    "                f for f in os.listdir(task_path)\n",
    "                if f.lower().endswith('.pickle')\n",
    "            ]\n",
    "\n",
    "            if not pickles:\n",
    "                print(\"   (no .pickle files here)\")\n",
    "                continue\n",
    "\n",
    "            for fname in pickles:\n",
    "                full = os.path.join(task_path, fname)\n",
    "                print(f\"  • {fname}\", end='  ')\n",
    "                try:\n",
    "                    # Let pandas handle the load (it remaps moved modules)\n",
    "                    data = pd.read_pickle(full)\n",
    "                    # Peek if DataFrame-like\n",
    "                    if hasattr(data, 'head'):\n",
    "                        print(\"\\n\", data.head(), \"\\n\")\n",
    "                    else:\n",
    "                        print(f\"(loaded: {type(data).__name__})\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ couldn’t read {fname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧪 Data from controlled laboratory experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load Raw data from Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lab_data_Raw(\n",
    "    base_path: str,\n",
    "    participants: list[str],\n",
    "    modalities: list[str] = ['Empatica', 'Muse', 'Psychopy', 'Stretched']\n",
    ") -> None:\n",
    "    \n",
    "    for p in participants:\n",
    "        lab_root = os.path.join(base_path, p, 'Lab')\n",
    "        print(f\"\\n=== Participant: {p} (Lab) ===\")\n",
    "\n",
    "        if not os.path.isdir(lab_root):\n",
    "            print(f\"   ✗ No Lab data found for participant {p}\")\n",
    "            continue\n",
    "\n",
    "        raw_root = os.path.join(lab_root, 'Raw')\n",
    "        for mod in modalities:\n",
    "            print(f\"\\n-- {mod} CSV files --\")\n",
    "            mod_path = os.path.join(raw_root, mod)\n",
    "\n",
    "            if not os.path.isdir(mod_path):\n",
    "                print(f\"   ✗ Missing folder: {mod_path}\")\n",
    "                continue\n",
    "\n",
    "            csvs = [f for f in os.listdir(mod_path)\n",
    "                    if f.lower().endswith('.csv')]\n",
    "            if not csvs:\n",
    "                print(\"   (no CSVs here)\")\n",
    "                continue\n",
    "\n",
    "            for fname in csvs:\n",
    "                full = os.path.join(mod_path, fname)\n",
    "                print(f\"  • {fname}\")\n",
    "                try:\n",
    "                    df = pd.read_csv(full)\n",
    "                    print(df.head(), \"\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠ Couldn’t read {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion to Load Labeled, Preprocessed, Features data from Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lab_data_labeled_preprocessed_features(\n",
    "    base_path: str,\n",
    "    participants: list[str],\n",
    "    lab_subfolder: str\n",
    ") -> None:\n",
    "    \n",
    "    for p in participants:\n",
    "        print(f\"\\n=== Participant: {p} | Lab/{lab_subfolder} ===\")\n",
    "        root = os.path.join(base_path, p, 'Lab', lab_subfolder)\n",
    "\n",
    "        if not os.path.isdir(root):\n",
    "            print(f\"   ✗ No {lab_subfolder} data for {p}\")\n",
    "            continue\n",
    "\n",
    "        tasks = [d for d in os.listdir(root)\n",
    "                 if os.path.isdir(os.path.join(root, d))]\n",
    "        if not tasks:\n",
    "            print(\"   (no task folders here)\")\n",
    "            continue\n",
    "\n",
    "        for task in tasks:\n",
    "            task_path = os.path.join(root, task)\n",
    "            print(f\"\\n-- {task} --\")\n",
    "            pickles = [f for f in os.listdir(task_path)\n",
    "                       if f.lower().endswith('.pickle')]\n",
    "\n",
    "            if not pickles:\n",
    "                print(\"   (no .pickle files here)\")\n",
    "                continue\n",
    "\n",
    "            for fname in pickles:\n",
    "                full = os.path.join(task_path, fname)\n",
    "                print(f\"  • {fname}\", end='  ')\n",
    "                try:\n",
    "                    data = pd.read_pickle(full)\n",
    "                    if hasattr(data, 'head'):\n",
    "                        print(\"\\n\", data.head(), \"\\n\")\n",
    "                    else:\n",
    "                        print(f\"(loaded: {type(data).__name__})\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ couldn’t read {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🖥️ Output\n",
    "\n",
    "Run the relevent cell below to see your results.  \n",
    "Make sure you’ve set the `base_path` to where your data is stored 📂  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # !!!!!!!! 🚨🚨🚨🚨  Put your base path here  🚨🚨🚨🚨 \n",
    "    base_path = ' '\n",
    "\n",
    "    participants = get_participants(base_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Raw features in Situ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_situ_data_raw(base_path, participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Preprocessed output in Situ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_situ_data_labeled_preprocessed_features(base_path, participants, 'Preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Features output in Situ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_situ_data_labeled_preprocessed_features(base_path, participants, 'Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Labeled output in Situ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_situ_data_labeled_preprocessed_features(base_path, participants, 'Labeled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the raw output in Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_lab_data_Raw(base_path, participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Preprocessed output in Lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_lab_data_labeled_preprocessed_features(base_path, participants, 'Preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Features output in Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_lab_data_labeled_preprocessed_features(base_path, participants, 'Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to see the Labeled output in Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_lab_data_labeled_preprocessed_features(base_path, participants, 'Labeled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psychopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
